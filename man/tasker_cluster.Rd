% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tasker_cluster.R
\name{tasker_cluster}
\alias{tasker_cluster}
\title{Initialize parallel cluster with tasker configuration}
\usage{
tasker_cluster(
  ncores = NULL,
  packages = NULL,
  export = NULL,
  setup_expr = NULL,
  envir = parent.frame(),
  load_all = FALSE
)
}
\arguments{
\item{ncores}{Number of cores (default: auto-detect as detectCores() - 2, max 32)}

\item{packages}{Character vector of package names to load on workers (optional).
The tasker package is always loaded automatically. Additionally, all packages
currently attached in the main session (excluding base packages) are
automatically detected and loaded on workers.}

\item{export}{Character vector of object names to export to workers (optional).
The active run_id is always exported automatically if one exists.}

\item{setup_expr}{Expression to evaluate on each worker after packages are loaded
(e.g., for creating database connections). The expression should return NULL
or a serializable value to avoid serialization errors. (optional)}

\item{envir}{Environment to export objects from (default: parent.frame())}

\item{load_all}{If TRUE, call devtools::load_all() on workers (default: FALSE)}
}
\value{
Cluster object from parallel::makeCluster()
}
\description{
This function simplifies setting up parallel processing with tasker by
automatically handling package loading, object export, and context initialization
on all workers. It encapsulates the common pattern of cluster setup, reducing
boilerplate from 8-10 lines to 1-2 lines.
}
\details{
All packages currently attached in the main session (except base packages) are
automatically loaded on workers, eliminating the need to manually specify common
dependencies.
}
\examples{
\dontrun{
# Simple setup with auto-detection
# All currently attached packages will be loaded on workers
library(dplyr)
library(sf)
cl <- tasker_cluster()
results <- parLapply(cl, items, worker_function)
stop_tasker_cluster(cl)

# With custom packages and objects
# Both specified packages and attached packages will be loaded
cl <- tasker_cluster(
  ncores = 16,
  packages = c("dplyr", "sf"),
  export = c("counties", "data_path")
)

# With database connections
cl <- tasker_cluster(
  ncores = 8,
  setup_expr = quote({
    devtools::load_all()
    con <- dbConnectBBC(mode = "rw")
    NULL  # Important: return NULL to avoid serialization error
  })
)

# Full example with context
task_start("PROCESS", "County Analysis")
subtask_start("Process counties", items_total = 3143)

cl <- tasker_cluster(ncores = 16, export = "counties")
results <- parLapplyLB(cl, counties, function(county_fips) {
  result <- process_county(county_fips)
  subtask_increment(increment = 1, quiet = TRUE)
  return(result)
})
stop_tasker_cluster(cl)

subtask_complete()
task_complete()
}
}
\seealso{
\code{\link[=export_tasker_context]{export_tasker_context()}} to add context to existing clusters,
\code{\link[=stop_tasker_cluster]{stop_tasker_cluster()}} to properly shut down clusters,
\code{\link[=subtask_increment]{subtask_increment()}} for atomic progress updates in parallel workers
}
